{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence to sequence model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5XVCtgY/0koDNbVoKJTJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpius/MachineTranslation/blob/main/Sequence_to_sequence_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "KgovuPAxDL3w",
        "outputId": "7dc5aeb7-770c-4b5c-b019-368295015f09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "try:\n",
        "  COLAB = True\n",
        "  import tensorflow as tf\n",
        "  print(f\"You are using Colab with tensorflow version {tf.__version__}\")\n",
        "except Exception as e:\n",
        "  COLAB = False\n",
        "  print(f\"{type(e)}: {e}\\n....Please Load Your Drive....\")\n",
        "\n",
        "def time_fmt(x):\n",
        "  h = int(x / (60 * 60))\n",
        "  m = int(x % (60 * 60) / 60)\n",
        "  s = int(x % 60)\n",
        "  return f\"{h}: {m:>03}: {s:>05.2f}\"\n",
        "\n",
        "time_fmt(240.892)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "You are using Colab with tensorflow version 2.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0: 004: 00.00'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMwrOKsREtDn"
      },
      "source": [
        "import time, io, os, re, unicodedata\n",
        "import matplotlib as mlp\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.ticker as ticker\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbZGLDLnFgwR"
      },
      "source": [
        "#Lets build an encoder-decoder network for machine translation"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDu5C5pfFtKG"
      },
      "source": [
        "#Importing and preprocessing the data\n",
        "#We will train a machine to translate spanish language to english\n",
        "#It is a simple MT with attention mechanism to learn variable/words contribution"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utqRIxdjF5vr"
      },
      "source": [
        "folder_path = tf.keras.utils.get_file(fname = \"spa-eng.zip\", origin = \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "                                      extract = True)\n",
        "file_path = os.path.dirname(folder_path) + \"/spa-eng/spa.txt\""
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Yiq0qiHyNH"
      },
      "source": [
        "#Change the unicode data format into ascii format:\n",
        "def ascii_fmt(t):\n",
        "  return \"\".join(k for k in unicodedata.normalize('NFD',t) if unicodedata.category(k) != 'Mn')"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR7BVnjGIrPg"
      },
      "source": [
        "def preprocess_text(t):\n",
        "  '''We do some cleaning and marking the start and the end of each sentence'''\n",
        "  t = ascii_fmt(t.lower().strip()) #Convert to lower cases and strip the white spaces\n",
        "  t = re.sub(r\"([?,!.多])\", r\" \\1 \", t)\n",
        "  t = re.sub(r'[\" \"]+', \" \", t)\n",
        "  t = re.sub(r'[^a-zA-Z?多,.!]+',\" \", t) # For each sentence we replace the everthing else except the one listed with a white space\n",
        "  t = t.strip() #Strip the white spaces\n",
        "  t = '<start>' + t + '<end>' #Marking the start and the end of each sentence with start, end\n",
        "  return t"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHWwHWiEI_Pz"
      },
      "source": [
        "#Testing the above function if it works as intended:\n",
        "en_verse = u\"May I borrow this book?\"\n",
        "sp_verse = u\"多Puedo tomar prestado este libro?\""
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O80oUj8ZJOJh"
      },
      "source": [
        "en_out = preprocess_text(en_verse)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oda7vrpQJV3T"
      },
      "source": [
        "sp_out = preprocess_text(sp_verse)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu2ja5tPJaZs",
        "outputId": "ea44f7c6-b6a5-4cec-d085-8d11a5bce1f5"
      },
      "source": [
        "print(en_out)\n",
        "print()\n",
        "print(sp_out)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start>may i borrow this book ?<end>\n",
            "\n",
            "<start>多 puedo tomar prestado este libro ?<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqif5h7WJg0I"
      },
      "source": [
        "#Create sentences pairs for english-spanish side by side"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7v5s_DjJyAo"
      },
      "source": [
        "def data_creator(path, sample_size):\n",
        "  lines = io.open(path, encoding = 'UTF-8').read().strip().split(\"\\n\")\n",
        "  words_pair = [[preprocess_text(t) for t in line.split(\"\\t\")] for line in lines[:sample_size]]\n",
        "  return zip(*words_pair)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--01oNVVJ2uk"
      },
      "source": [
        "#Applying the function\n",
        "sample_size = 50000"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSiMh7VHKQgw"
      },
      "source": [
        "#Load the sample of size 50000\n",
        "eng_text, spa_text = data_creator(file_path,sample_size )"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGKQ1-rxKqx1",
        "outputId": "9f4a017e-aa5c-4dba-cebd-99216a9e9be6"
      },
      "source": [
        "print(f\"English text is : {eng_text[-1]}\")\n",
        "print()\n",
        "print(f\"Spanish text is: {spa_text[-1]}\")"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English text is : <start>the people are so friendly .<end>\n",
            "\n",
            "Spanish text is: <start>la gente es muy amable .<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAo94cJhK9-m"
      },
      "source": [
        "#Tokenize and padding the data to the right"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAziKOkpMiu-"
      },
      "source": [
        "def ln_tokenization(text):\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = '')\n",
        "  tokenizer.fit_on_texts(text)\n",
        "  tensor = tokenizer.texts_to_sequences(text)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding = 'post')\n",
        "  return tensor, tokenizer"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTIrIFhRN5-e"
      },
      "source": [
        "#Load the cleaned and prepared dataset for training our MT-model"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV1YtRAxODXU"
      },
      "source": [
        "def load_clean_data(path, sample_size = None):\n",
        "  target_lang, input_lang = data_creator(file_path, sample_size)\n",
        "  input_tensor, input_tokenizer = ln_tokenization(input_lang)\n",
        "  target_tensor, target_tokenizer = ln_tokenization(target_lang)\n",
        "  return input_tensor, target_tensor, input_tokenizer, target_tokenizer"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZD-McH6PQPY"
      },
      "source": [
        "sample_size = 50000\n",
        "input_tensor, target_tensor, input_lang, target_lang = load_clean_data(file_path, sample_size)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k_Ygw_tPs71",
        "outputId": "1624e767-7e31-4b53-eb76-229030b7f335"
      },
      "source": [
        "print(f\"Max_len_input: {input_tensor.shape[1]}, Max_len_output: {target_tensor.shape[1]}\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max_len_input: 14, Max_len_output: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvMtRFsYRCoX"
      },
      "source": [
        "#Split the data for training and testing \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmYqwpZARd_D"
      },
      "source": [
        "x_train, x_test, y_train,y_test = train_test_split(input_tensor, target_tensor, test_size = 0.2)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqJO7IR7SAzp",
        "outputId": "2c495927-4f95-46ee-9677-1944899643cc"
      },
      "source": [
        "print(f\"x_train_shape: {x_train.shape}, y_train_shape: {y_train.shape}\\nx_test_shape: {x_test.shape}, y_test_shape: {y_test.shape}\")"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train_shape: (40000, 14), y_train_shape: (40000, 10)\n",
            "x_test_shape: (10000, 14), y_test_shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-dBHEP3S5vv"
      },
      "source": [
        "#Map every word in a text to an index (number)\n",
        "def create_index(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t != 0:\n",
        "      print(\"%d---->%s\" %(t, lang.index_word[t]))"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQpwCdsgTTqB",
        "outputId": "44a9d3b3-8684-4fef-f197-029c1066d5f6"
      },
      "source": [
        "#Testing the map function\n",
        "print('Input language, index-word mapping')\n",
        "create_index(input_lang, x_train[10])"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input language, index-word mapping\n",
            "1235----><start>abre\n",
            "13---->la\n",
            "186---->puerta\n",
            "8---->de\n",
            "1761---->golpe\n",
            "1---->.<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98i8givrUBj4",
        "outputId": "92256aa9-ed53-4abc-8c12-84029ef81d5e"
      },
      "source": [
        "print(\"output language, index-word\")\n",
        "create_index(target_lang, y_train[10])"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output language, index-word\n",
            "2843----><start>kick\n",
            "11---->the\n",
            "215---->door\n",
            "25---->in\n",
            "1---->.<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2COumFQzUdD5"
      },
      "source": [
        "#Creating a tensorflow data type for easy training"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAzfHCGyU9_1"
      },
      "source": [
        "batch_size = 64\n",
        "BUFFER = len(x_train)\n",
        "step_per_epoch = BUFFER // batch_size\n",
        "units = 1024\n",
        "embedding_dim = 512\n",
        "input_voc_size = len(input_lang.word_index) + 1\n",
        "output_voc_size = len(target_lang.word_index) + 1\n",
        "\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKz-5pBfWWRc"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BUFFER)\n",
        "train_data = train_data.batch(batch_size, drop_remainder = True)\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_data = test_data.batch(batch_size, drop_remainder = True)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg8TciqVXScR"
      },
      "source": [
        "#The above datasets are ready for training:\n",
        "#We employ model subclassing to build both encoder and decoder network\n",
        "#We the use layer subclassing to construct an attention mechanism\n",
        "#In this project we will employ additive attention (Bhanadau's attention) with 3 parameters to be learnt"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAFGMWTTG8eF"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, enc_units, voc_size, batch_size, embedding_dim, name = 'encoder', **kwargs):\n",
        "    super(Encoder, self).__init__(name = name, **kwargs)\n",
        "    self.enc_units = enc_units\n",
        "    self.batch_size = batch_size\n",
        "    self.enc_embedding = tf.keras.layers.Embedding(input_dim = voc_size, output_dim = embedding_dim, name = 'encoder_embd')\n",
        "    self.enc_gru = tf.keras.layers.GRU(units = self.enc_units, kernel_initializer = 'glorot_uniform',\n",
        "                                       return_state = True, return_sequences = True,\n",
        "                                       recurrent_dropout = 0.5, dropout = 0.5,\n",
        "                                       name = 'encoder_gru')\n",
        "  \n",
        "  def call(self, inputs, hidden):\n",
        "    inputs = self.enc_embedding(inputs)\n",
        "    enc_out, enc_hidden = self.enc_gru(inputs, initial_state = hidden)\n",
        "    return enc_out, enc_hidden\n",
        "  \n",
        "  def hidden_initializer(self):\n",
        "    return tf.zeros(shape = (self.batch_size, self.enc_units))\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXEq1g0OJHZD"
      },
      "source": [
        "#Instantiate and testing the encoder"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUMVG4TsJMp7",
        "outputId": "5d1c316d-06ff-4584-9c05-acd3bc655fb7"
      },
      "source": [
        "encoder = Encoder(units, input_voc_size, batch_size,embedding_dim, name = 'encoder')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer encoder_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_1W83lqKbZE"
      },
      "source": [
        "sample_x_batch_train, sample_y_batch_train = next(iter(train_data))"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csor4vqrJfR5"
      },
      "source": [
        "hidden_state = encoder.hidden_initializer()"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Dhm8wUKtMx"
      },
      "source": [
        "sample_enc_out, sample_enc_hidden = encoder(sample_x_batch_train, hidden_state)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osTsX5JKK1xX",
        "outputId": "edab975f-48d8-4344-e226-4f01dd01d59b"
      },
      "source": [
        "print(f\"sample_enc_out_shape: {sample_enc_out.shape}\\nsample_enc_hidden_shape: {sample_enc_hidden.shape}\")"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_enc_out_shape: (64, 14, 1024)\n",
            "sample_enc_hidden_shape: (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jp-8uBeLHSg"
      },
      "source": [
        "#The decoder network without an attention"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVArScicLM1X"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, dec_units, embedding_dim, voc_size, batch_size, name = 'decoder', **kwargs):\n",
        "    super(Decoder, self).__init__(name = name, **kwargs)\n",
        "    self.dec_units = dec_units\n",
        "    self.batch_size = batch_size\n",
        "    self.dec_embedding = tf.keras.layers.Embedding(input_dim = voc_size, output_dim = embedding_dim, name = 'decoder_embd')\n",
        "    self.dec_gru = tf.keras.layers.GRU(units = self.dec_units, kernel_initializer = 'glorot_uniform',\n",
        "                                       return_state = True, return_sequences = True,\n",
        "                                       recurrent_dropout = 0.5, dropout = 0.5,\n",
        "                                       name = 'decoder_gru')\n",
        "    self.fc = tf.keras.layers.Dense(units = voc_size, kernel_initializer = 'glorot_uniform',activation = 'softmax')\n",
        "  \n",
        "  def call(self, inputs, hidden):\n",
        "    inputs = self.dec_embedding(inputs)\n",
        "    dec_out, dec_hidden = self.dec_gru(inputs, initial_state = hidden)\n",
        "    dec_out = tf.reshape(dec_out, shape = (-1, dec_out.shape[2]))\n",
        "    inputs = self.fc(dec_out)\n",
        "    return inputs, dec_hidden"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebeMufO1Q40X"
      },
      "source": [
        "#Instantiate the decoder and testing using the sample batch encoder output "
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8X-3CF8RAZe",
        "outputId": "e27a1445-cb35-4868-a9c5-8af226b5d3ee"
      },
      "source": [
        "decoder = Decoder(units, embedding_dim,output_voc_size,batch_size,name = 'decoder')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer decoder_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fijdeMcbRaxu"
      },
      "source": [
        "sample_dec_out, sample_dec_hidden = decoder(tf.random.uniform(shape = (batch_size,1)),sample_enc_hidden)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMIzMauURu1e",
        "outputId": "0af88754-6808-4b6e-886b-1a91b2a13101"
      },
      "source": [
        "print(f\"sample_dec_out_shape: {sample_dec_out.shape}\\nsample_dec_hidden_shape: {sample_dec_hidden.shape}\")"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_dec_out_shape: (64, 7525)\n",
            "sample_dec_hidden_shape: (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV0pNiT6SH9P"
      },
      "source": [
        "#Dotproduct attention:\n",
        "class DotproductAttention(tf.keras.layers.Layer):\n",
        "  def call(self, query, values):\n",
        "    query_expanded = tf.expand_dims(query,1)# adding the time dimension\n",
        "    score = query_expanded * values\n",
        "    score = tf.reduce_sum(score, axis = 2)\n",
        "    score = tf.expand_dims(score, axis = 2)\n",
        "    attention_wt = tf.nn.softmax(score, axis = 1)\n",
        "    context = attention_wt * values\n",
        "    context_vector = tf.reduce_sum(context, axis = 1)\n",
        "    return context_vector, attention_wt\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKUHccaglRoh"
      },
      "source": [
        "#Testing the attention \n",
        "attention_layer = DotproductAttention()\n",
        "sample_context_vector, sample_attention_wt = attention_layer(sample_enc_hidden, sample_enc_out)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzjkgapPlupU",
        "outputId": "f541818d-93be-47ac-dc08-cfc698f3e21d"
      },
      "source": [
        "print(f\"sample_context_vector_shape: {sample_context_vector.shape}:\\nsample_attention_wt_shape: {sample_attention_wt.shape}\")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_context_vector_shape: (64, 1024):\n",
            "sample_attention_wt_shape: (64, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfB16Wl4mJTa"
      },
      "source": [
        "#Bhanadau attention:\n",
        "class BhanadauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, name = 'bhanadau',**kwargs):\n",
        "    super(BhanadauAttention, self).__init__(name = name, **kwargs)\n",
        "    self.W1 = tf.keras.layers.Dense(units = units)\n",
        "    self.W2 = tf.keras.layers.Dense(units = units)\n",
        "    self.V = tf.keras.layers.Dense(units = 1)\n",
        "  \n",
        "  def call(self, query, values):\n",
        "    query_expanded = tf.expand_dims(query, 1) #Add the time dimension for the hidden state\n",
        "    score = self.V(tf.nn.tanh(self.W1(query_expanded) + self.W2(values)))\n",
        "    attention_wt = tf.nn.softmax(score, axis = 1)\n",
        "    context = attention_wt * values\n",
        "    context_vector = tf.reduce_sum(context, axis = 1)\n",
        "    return context_vector, attention_wt"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clD-FIO_xIzl"
      },
      "source": [
        "#Instantiate and testing the bhanadau attention"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MusR45ZxxQtN"
      },
      "source": [
        "bhnadau = BhanadauAttention(10, name = 'bhanadau')"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KvYqoB3xYLX"
      },
      "source": [
        "sample_bhanadau_context_vec, sample_bhanadau_attention_wt = bhnadau(sample_enc_hidden, sample_enc_out)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n2_4MxFxuvk",
        "outputId": "cb16a62c-fb47-4c7e-aef1-78ff7ded4d05"
      },
      "source": [
        "print(f\"sample_bhanadau_context_vec_shape: {sample_bhanadau_context_vec.shape}\\nsample_nhanadau_attention_wt_shape: {sample_bhanadau_attention_wt.shape}\")"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_bhanadau_context_vec_shape: (64, 1024)\n",
            "sample_nhanadau_attention_wt_shape: (64, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXQuzwy3yCrH"
      },
      "source": [
        "#Decoder with attention:"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqsfNwUbyHXj"
      },
      "source": [
        "class DecoderWithAttention(tf.keras.Model):\n",
        "  def __init__(self,dec_units, voc_size, batch_size,embedding_dim,attention_layer = None, name = 'dec_with_attention',**kwargs):\n",
        "    super(DecoderWithAttention, self).__init__(name = name, **kwargs)\n",
        "    self.batch_size = batch_size\n",
        "    self.dec_units = dec_units\n",
        "    self.dec_embedding = tf.keras.layers.Embedding(input_dim = voc_size, output_dim = embedding_dim, name = 'dec_embedding')\n",
        "    self.dec_gru = tf.keras.layers.GRU(units = self.dec_units, kernel_initializer = 'glorot_uniform',\n",
        "                                       return_state = True, return_sequences = True,\n",
        "                                       recurrent_dropout = True, dropout = True,\n",
        "                                       name = 'dec_gru')\n",
        "    self.fc = tf.keras.layers.Dense(units = voc_size)\n",
        "    self.attention = attention_layer\n",
        "\n",
        "  def call(self,inputs,enc_hidden, enc_out):\n",
        "    inputs = self.dec_embedding(inputs)\n",
        "    attention_wt = None\n",
        "    if self.attention:\n",
        "      context_vector, attention_wt = self.attention(enc_hidden, enc_out)\n",
        "      inputs = tf.concat([tf.expand_dims(context_vector, 1), inputs], axis = -1)\n",
        "      dec_out, dec_hidden_state = self.dec_gru(inputs, initial_state = enc_hidden)\n",
        "      dec_out = tf.reshape(dec_out, shape = (-1, dec_out.shape[2])) \n",
        "      inputs = self.fc(dec_out)\n",
        "      return inputs, dec_hidden_state, attention_wt"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJxUEryf2dXa"
      },
      "source": [
        "#Instantiate and testing the decoder with dotproduct attention"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLUFwZDz2kRm",
        "outputId": "c27af21f-f198-4567-dee6-8f8181afd7eb"
      },
      "source": [
        "decoder_with_attention = DecoderWithAttention(units, output_voc_size,batch_size, embedding_dim,attention_layer= attention_layer, name = 'dec_attn')"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer dec_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDhlzOSF3AnY"
      },
      "source": [
        "sample_dec_out_with_attn, sample_dec_hidden_with_attn,sample_attent_wt = decoder_with_attention(tf.random.uniform(shape = (batch_size,1)), sample_enc_hidden, sample_enc_out)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNclReAd3927",
        "outputId": "0de35e1e-40c2-4461-ab83-d52dd836529a"
      },
      "source": [
        "print(f\"sample_dec_hidden_with_attn_shape: {sample_dec_hidden_with_attn.shape}\\nsample_dec_out_with_attn_shape: {sample_dec_out_with_attn.shape}\\nsample_attn_wt-shape: {sample_attent_wt.shape}\")"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_dec_hidden_with_attn_shape: (64, 1024)\n",
            "sample_dec_out_with_attn_shape: (64, 7525)\n",
            "sample_attn_wt-shape: (64, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ChcQtRF9Cnx"
      },
      "source": [
        "#Training loop from scratch: Tomorrow"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}